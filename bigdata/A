Q1(a)
Explain the architecture of HDFS and describe the roles of the NameNode and DataNode.
Answer:
HDFS Architecture (Master–Slave):
• HDFS = Hadoop Distributed File System; used for reliable, scalable distributed
storage.
• Follows master–slave architecture:
o One active NameNode (master)
o Many DataNodes (slaves)
NameNode (Master):
• Stores metadata (file names, hierarchy, permissions, block locations).
• Manages file system namespace (directory tree).
• Coordinates operations like create, delete, rename files/directories.
• Does not store actual file data, only metadata in memory.
DataNodes (Slaves):
• Store actual data blocks on local disks.
• Serve read/write requests from clients and NameNode.
• Periodically send:
o Heartbeats (to confirm they’re alive)
o Block reports (which blocks they hold)
Data Storage Workflow:
• File is split into blocks (e.g., 128 MB).
• Each block is replicated across multiple DataNodes (default factor 3).
• NameNode tracks which DataNode has which block

Q1(b)
What is HBase? Compare it with traditional RDBMS and mention two use cases.
Answer:
What is HBase?
• HBase is a NoSQL, distributed, column-family store built on top of HDFS, inspired by
Google Bigtable.
• Designed for random real-time read/write access to big data.

HBase vs RDBMS:

Aspect    HBase (NoSQL)                        Traditional RDBMS
Schema    Schema-flexible (column families)    Fixed schema (tables with fixed
columns)
Data Model Column family, sparse, wide tables   Relational (rows/columns,normalized)
Joins     Not natively supported                Supported via SQL
Scaling   Horizontal scale over commodityservers       Mostly vertical; scale-up
Transactions     Limited atomicity (row-level)         ACID transactions
Query            Language No SQL; uses APIs & filters           SQL


Two Use Cases:
1. Time-series / log data storage
o Clickstreams, sensor data, server logs where data is large and append-heavy.
2. Real-time lookup for large datasets
o User profiles, recommendation data, key-based access with low latency

Q1(c)
What is YARN in Hadoop? Explain its function and list its key components.
Answer:
YARN (Yet Another Resource Negotiator):
• Acts as cluster resource management and job scheduling layer in Hadoop.
• Decouples resource management from data processing models, allowing different
engines (MapReduce, Spark, etc.) to run on the same cluster.

Main Functions:
• Track available resources (CPU, memory) across nodes.
• Allocate resources to applications.
• Schedule tasks and monitor application lifecycle.
Key Components:
1. ResourceManager (RM):
o Central authority for resource allocation.
o Runs Scheduler (allocates containers) and ApplicationManager.
2. NodeManager (NM):
o Runs on each worker node.
o Manages containers.
o Reports resource usage and health to RM.
3. ApplicationMaster (AM):
o One per application/job.
o Negotiates resources from RM.
o Coordinates tasks’ execution inside containers on NMs.
4. Containers:
o Resource bundles (CPU + RAM) granted to an AM or task.
o Execution environment for individual tasks.



Q1(d)
What is the role of DAG (Directed Acyclic Graph) in Apache Spark? How does it improve job
execution compared to MapReduce?
Answer:
Role of DAG in Spark:
• Spark builds a DAG of stages and tasks for each job.
• Nodes = RDD/DataFrame operations, edges = dependencies.
• The DAG describes how data flows through transformations.
How it improves over MapReduce:
1. Global Optimization:
o Spark’s DAG scheduler can optimize across multiple operations (e.g.,
pipelining, collapsing stages).
o MapReduce treats each job independently (map → shuffle → reduce).

2. In-Memory Computation:
o Intermediate results can be cached in memory (RDD/DataFrame cache).
o MapReduce writes intermediates to disk between every phase.
3. Less Disk I/O & Latency:
o Fewer read/write cycles → faster execution.
o Especially beneficial for iterative algorithms and interactive queries.
4. Pipelining:
o Multiple narrow transformations can run in a single stage.
o MapReduce has fixed map/reduce stages with disk in-between.
